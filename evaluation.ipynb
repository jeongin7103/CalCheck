{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3tn3dLXxcZi4BuCk4gYlo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeongin7103/CalCheck/blob/main/evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlvsxwZaaa-k",
        "outputId": "e21c968a-1ff1-4c36-dfc2-01f9a9c4f91e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/SSD_detection')"
      ],
      "metadata": {
        "id": "XlDVCh_magVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import *\n",
        "from datasets import CustomDataset\n",
        "from tqdm import tqdm\n",
        "from pprint import PrettyPrinter"
      ],
      "metadata": {
        "id": "Wd1LYHs9agXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Good formatting when printing the APs for each class and mAP\n",
        "pp = PrettyPrinter()\n",
        "\n",
        "# Parameters\n",
        "data_folder = '/content/drive/MyDrive/SSD_detection/test'\n",
        "batch_size = 4\n",
        "workers = 4\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "checkpoint = '/content/drive/MyDrive/SSD_detection/checkpoints/checkpoint_ssd300_epoch_19.pth.tar'"
      ],
      "metadata": {
        "id": "qSFmGG6Fagco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model checkpoint that is to be evaluated\n",
        "checkpoint = torch.load(checkpoint, map_location=torch.device('cpu'))\n",
        "model = checkpoint['model']\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "Li414cVcage4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Switch to eval mode\n",
        "model.eval()\n",
        "\n",
        "# Load test data\n",
        "test_dataset = CustomDataset(data_folder, split='test')\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
        "                                          collate_fn=test_dataset.collate_fn, pin_memory=True)"
      ],
      "metadata": {
        "id": "o8wa1j9BaghF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(test_loader, model):\n",
        "    \"\"\"\n",
        "    Evaluate.\n",
        "\n",
        "    :param test_loader: DataLoader for test data\n",
        "    :param model: model\n",
        "    \"\"\"\n",
        "\n",
        "    # Make sure it's in eval mode\n",
        "    model.eval()\n",
        "\n",
        "    # Lists to store detected and true boxes, labels, scores\n",
        "    det_boxes = list()\n",
        "    det_labels = list()\n",
        "    det_scores = list()\n",
        "    true_boxes = list()\n",
        "    true_labels = list()\n",
        "    true_difficulties = list()  # it is necessary to know which objects are 'difficult', see 'calculate_mAP' in utils.py\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Batches\n",
        "        for i, (images, boxes, labels) in enumerate(tqdm(test_loader, desc='Evaluating')):\n",
        "            images = images.to(device)  # (N, 3, 300, 300)\n",
        "\n",
        "            # Forward prop.\n",
        "            predicted_locs, predicted_scores = model(images)\n",
        "\n",
        "            # Detect objects in SSD output\n",
        "            det_boxes_batch, det_labels_batch, det_scores_batch = model.detect_objects(predicted_locs, predicted_scores,\n",
        "                                                                                       min_score=0.01, max_overlap=0.45,\n",
        "                                                                                       top_k=200)\n",
        "            # Evaluation MUST be at min_score=0.01, max_overlap=0.45, top_k=200 for fair comparision with the paper's results and other repos\n",
        "\n",
        "            # Store this batch's results for mAP calculation\n",
        "            boxes = [b.to(device) for b in boxes]\n",
        "            labels = [l.to(device) for l in labels]\n",
        "\n",
        "            det_boxes.extend(det_boxes_batch)\n",
        "            det_labels.extend(det_labels_batch)\n",
        "            det_scores.extend(det_scores_batch)\n",
        "            true_boxes.extend(boxes)\n",
        "            true_labels.extend(labels)\n",
        "\n",
        "        # Calculate mAP\n",
        "        APs, mAP = calculate_mAP(det_boxes, det_labels, det_scores, true_boxes, true_labels)\n",
        "\n",
        "    # Print AP for each class\n",
        "    pp.pprint(APs)\n",
        "\n",
        "    print('\\nMean Average Precision (mAP): %.3f' % mAP)"
      ],
      "metadata": {
        "id": "DHPzQalta-gI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(test_loader, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbzzcHj8a-6h",
        "outputId": "18fc375b-68eb-49d6-c1a8-17c42b88a03f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 250/250 [24:16<00:00,  5.83s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Kohlrabi': 0.8771983981132507,\n",
            " 'Mushroom': 0.926325261592865,\n",
            " 'Paprika': 0.7396257519721985,\n",
            " 'Pimento': 0.4829806387424469,\n",
            " 'Pumpkin': 0.9344001412391663,\n",
            " 'Tomato': 0.9296153783798218,\n",
            " 'apple': 0.8561944365501404,\n",
            " 'blueberry': 0.8924987316131592,\n",
            " 'cherry': 0.7098320722579956,\n",
            " 'chestnuts': 0.8994967937469482,\n",
            " 'chicory': 0.9920255541801453,\n",
            " 'grape': 0.9398550391197205,\n",
            " 'grapefruit': 0.8048553466796875,\n",
            " 'mango': 0.5383621454238892,\n",
            " 'melon': 0.8975515365600586,\n",
            " 'peach': 0.9330011606216431,\n",
            " 'pepper': 0.6311404705047607,\n",
            " 'plum': 0.9017970561981201,\n",
            " 'strawberry': 0.9217002391815186,\n",
            " 'yam': 0.8972849249839783}\n",
            "\n",
            "Mean Average Precision (mAP): 0.835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5F_RVrp5Oyw6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}